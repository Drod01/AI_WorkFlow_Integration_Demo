# AI Workflow Integration Demo

Project Description:
- Build and support **AI/ML components**
- Integrate **LLMs** into enterprise-style **REST APIs**
- Apply **prompt engineering** and **chaining**
- Combine **human + system + AI** workflow orchestration
- Use **embeddings** and a **vector database** for semantic retrieval
- Provide **explainability** for ML predictions
- Package with **Docker** and a starter **CI/CD (GitHub Actions)**



---

## âœ¨ What This Project Demonstrates

- **FastAPI microservice** with endpoints:
  - `POST /ask-llm` â€“ LLM-backed financial FAQ & assistant
  - `POST /classify-fraud` â€“ Binary fraud text classifier (scikit-learn)
  - `POST /semantic-search` â€“ FAISS-backed similarity search over past Q&A
  - `POST /explain` â€“ SHAP explanation for a given classifier prediction
  - `GET /health` â€“ Healthcheck
- **Prompt chaining** â€“ System â†’ Guardrails â†’ User â†’ Post-processing
- **Vector DB (FAISS)** â€“ Flexible embedding layer with **SentenceTransformers** fallback to **TFâ€‘IDF** when transformers aren't available
- **Human-in-the-loop routing** â€“ Route suspicious/high-risk outputs to human review
- **Dockerized** â€“ One-line build & run
- **CI/CD** â€“ Lint + tests on push via GitHub Actions
- **Clear codebase** â€“ Well-structured modules, pydantic schemas, unit tests

---

## ğŸ§± Project Structure

```
ai_workflow_integration_demo/
â”‚â”€â”€ app/
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ schemas.py
â”‚   â”œâ”€â”€ llm_service.py
â”‚   â”œâ”€â”€ fraud_model.py
â”‚   â”œâ”€â”€ vector_store.py
â”‚   â”œâ”€â”€ explainability.py
â”‚   â””â”€â”€ workflow.py
â”‚
â”‚â”€â”€ data/
â”‚   â”œâ”€â”€ sample_fraud.csv
â”‚   â””â”€â”€ seed_knowledge.csv
â”‚
â”‚â”€â”€ models/
â”‚   â””â”€â”€ fraud_classifier.pkl
â”‚
â”‚â”€â”€ tests/
â”‚   â””â”€â”€ test_api.py
â”‚
â”‚â”€â”€ .github/workflows/ci.yml
â”‚â”€â”€ Dockerfile
â”‚â”€â”€ requirements.txt
â”‚â”€â”€ README.md
```

---

## ğŸš€ Quickstart

### 1) Local (Python 3.10+)
```bash
python -m venv .venv
source .venv/bin/activate   # Windows: .venv\Scripts\activate
pip install --upgrade pip
pip install -r requirements.txt

# (Optional) Use OpenAI - set your key:
# export OPENAI_API_KEY=sk-...

# Run API
uvicorn app.main:app --reload

# Open interactive docs:
# http://127.0.0.1:8000/docs
```

> **Note**: If `sentence-transformers` model download is blocked, the service will automatically fall back to a local TFâ€‘IDF embedding backend.

### 2) Docker
```bash
docker build -t ai-workflow-demo .
docker run -p 8000:8000 --env OPENAI_API_KEY=$OPENAI_API_KEY ai-workflow-demo
```

---

## ğŸ”Œ REST Endpoints

- `POST /ask-llm`
  - Body: `{ "query": "How do I increase my credit limit?", "context_ids": ["faq","fraud"] }`
  - Returns assistant message backed by LLM (OpenAI/Transformers) with safe guardrails and optional retrieval-augmented context.

- `POST /classify-fraud`
  - Body: `{ "text": "Wire money to this account now...", "threshold": 0.7 }`
  - Returns `{ "label": "fraud", "score": 0.92 }`

- `POST /semantic-search`
  - Body: `{ "query": "ACH transfer limits", "k": 5 }`
  - Returns top-k similar seed knowledge items.

- `POST /explain`
  - Body: `{ "text": "Please send gift cards to resolve your account issue." }`
  - Returns SHAP explanation values for the classifier.

- `GET /health`
  - Returns `{"status":"ok"}`

---

## ğŸ§  LLM Integration Strategy

The `llm_service` module attempts providers in this order:

1. **OpenAI API** (if `OPENAI_API_KEY` env is set)
2. **Hugging Face Transformers** (if available locally)
3. **Rule-based fallback** â€“ Safe, deterministic responses for offline demos

Prompt **chaining** injects:
- A **system prompt** (policies & style)
- **Guardrails** (refuse secrets, PII requests, etc.)
- **RAG context** (from FAISS/TFâ€‘IDF store)
- **User message**
- **Postâ€‘processor** (shorten, add disclaimers for risk)

---

## âš–ï¸ Explainability

Explainability is provided via **SHAP** for the scikit-learn pipeline (TFâ€‘IDF + LogisticRegression). See `app/explainability.py` and the `/explain` endpoint.

---

## ğŸ§ª Tests

Run tests:
```bash
pytest -q
```

---

## ğŸ› ï¸ Requirements / Software Used

- Python 3.10+
- FastAPI, Uvicorn
- scikit-learn, pandas, numpy
- sentence-transformers (optional), faiss-cpu (optional)
- shap (explainability)
- pydantic
- Docker
- GitHub Actions (CI)

See `requirements.txt` for full list.

---

## ğŸ”§ CI/CD (GitHub Actions)

- Lints and runs tests on every push/pull request
- Easy to extend for build/publish steps

---

## ğŸ§­ Roadmap Ideas

- Swap local FAISS with managed vector DB
- Add OAuth/JWT authentication
- Add Kafka/NATS for event-driven flows
- Container orchestration with Kubernetes
- Model registry via MLflow

---
